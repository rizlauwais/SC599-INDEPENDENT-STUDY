{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ddi6vpAv8OdV",
        "outputId": "0cc9a8fe-1e95-4d5e-9894-6f19c4b3bd95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install+Imports\n",
        "!pip -q install gradio joblib scikit-learn\n",
        "\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ],
      "metadata": {
        "id": "lA5-LLJ_8htj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load saved vectorizer + model\n",
        "import joblib\n",
        "\n",
        "clf_vectorizer = joblib.load(\"/content/drive/MyDrive/tfidf_vectorizer.pkl\")\n",
        "clf_model = joblib.load(\"/content/drive/MyDrive/tfidf_classifier.pkl\")\n",
        "\n",
        "print(\"âœ… Vectorizer + Classifier loaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ij6JEZr_nTq",
        "outputId": "6bf096a4-62a2-4222-ea7d-2ab195eb85a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.8.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.8.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Vectorizer + Classifier loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.8.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/tourism_multilingual_1500_FINAL.csv\")\n",
        "print(\"âœ… Dataset loaded:\", df.shape)\n",
        "print(\"Columns:\", list(df.columns))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQoP6VIlACi8",
        "outputId": "8959b042-33b4-4788-ab08-4a6f825f862e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Dataset loaded: (1500, 5)\n",
            "Columns: ['id', 'category', 'language', 'question', 'answer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Helper functions\n",
        "def detect_language(text):\n",
        "    for ch in text:\n",
        "        if '\\u0D80' <= ch <= '\\u0DFF':\n",
        "            return \"Sinhala\"\n",
        "        if '\\u0B80' <= ch <= '\\u0BFF':\n",
        "            return \"Tamil\"\n",
        "    return \"English\"\n",
        "\n",
        "def predict_category(text):\n",
        "    vec = clf_vectorizer.transform([text])\n",
        "    pred = clf_model.predict(vec)[0]\n",
        "    return pred, 1.0\n",
        "\n",
        "\n",
        "def retrieve_answer(q, cat, lang):\n",
        "    sub = df[(df[\"category\"] == cat) & (df[\"language\"] == lang)]\n",
        "    if len(sub) == 0:\n",
        "        return None\n",
        "\n",
        "    # ðŸ”¹ Exact match first\n",
        "    exact = sub[sub[\"question\"].str.lower() == q.lower()]\n",
        "    if len(exact) > 0:\n",
        "        return exact.iloc[0][\"answer\"]\n",
        "\n",
        "    # ðŸ”¹ Otherwise similarity search\n",
        "    vect = TfidfVectorizer()\n",
        "    X = vect.fit_transform(sub[\"question\"].astype(str))\n",
        "    qv = vect.transform([q])\n",
        "\n",
        "    best_idx = (X @ qv.T).toarray().argmax()\n",
        "    return sub.iloc[best_idx][\"answer\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "qcsMX7nWHF19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Chat function\n",
        "def chat_fn(message, history):\n",
        "    try:\n",
        "        lang = detect_language(message)\n",
        "        cat, conf = predict_category(message)\n",
        "        ans = retrieve_answer(message, cat, lang)\n",
        "\n",
        "        if ans is None:\n",
        "            return f\"Sorry, I couldn't find an answer for {lang} in category {cat}.\"\n",
        "\n",
        "        if conf < 0.5:\n",
        "            return \"Sorry, Iâ€™m not confident. Please rephrase your question.\"\n",
        "\n",
        "        return f\"{ans}\\n\\n(Category: {cat}, Confidence: {conf:.2f})\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Internal Error: {type(e).__name__}: {e}\"\n"
      ],
      "metadata": {
        "id": "tu9ICSQbHUNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.ChatInterface(\n",
        "    fn=chat_fn,\n",
        "    type=\"messages\",\n",
        "    title=\"AI-Powered Multilingual Tourism Chatbot (TF-IDF)\",\n",
        "    textbox=gr.Textbox(\n",
        "        lines=1,\n",
        "        placeholder=\"Ask in English / Sinhala / Tamil\",\n",
        "        submit_btn=True\n",
        "    )\n",
        ")\n",
        "\n",
        "demo.launch(share=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "fK_5Z0QLAtJu",
        "outputId": "6e65a457-b1ac-4447-9661-5ac973dba85b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3b4bf9a5b0bd074e30.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3b4bf9a5b0bd074e30.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}